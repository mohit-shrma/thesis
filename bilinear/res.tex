\section{Results and Discussion} \label{ch:bilinear:results}

\begin{table*}[bt]\footnotesize
  \centering
  \caption {Performance of \CF and Other Techniques on different datasets }
  \label{table_perf_datasets}    
  \setlength{\tabcolsep}{1.5em}
  \begin{threeparttable}
    \centering
    \begin{tabular}{ p{1.5cm}p{1.2cm}p{1cm}p{1cm}p{1.5cm}p{1cm}p{1cm} }
      \hline
      \multicolumn{1}{c}{\textbf{Method}} &
      \multicolumn{3}{c}{\textbf{\CULEXP}} &
      \multicolumn{3}{c}{\textbf{\MLHR}} \\
      %\hline
      \multicolumn{1}{c}{} &
      \multicolumn{1}{c}{Params} &
      \multicolumn{1}{c}{Rec@10} &
      \multicolumn{1}{c}{DCG@10} &
      \multicolumn{1}{c}{Params} &
      \multicolumn{1}{c}{Rec@10} &
      \multicolumn{1}{c}{DCG@10} \\
      \hline
	%\rule{-2pt}{3ex}
      \\
      \COSIM  & - & 0.1791  & 0.0684 & - & 0.0050  & 0.0199  \\
	%\rule{-2pt}{3ex}
      \\
      \RLFMI  & $h$=75, $\lambda$=0.001 & 0.0874 & 0.0424  & $h$=35,
	%\rule{-2pt}{3ex}
  $\lambda$=0.05 &
      \underline{0.012} &
      \underline{0.0466}\\
      \\
      %TODO: full set of regularization parameters
	%\rule{-2pt}{3ex}
      $\CFLIN_{bpr}$ & $l$=3, $\mu_1$=0.25, $\gamma$=0.1 & 0.2017 & 0.0791
	%\rule{-2pt}{3ex}
      & $l$=1, $\mu_1$=10, $\gamma$=50 & 0.0074 & 0.0233 \\ 
	%\rule{-2pt}{3ex}
      \\
      $\CF_{bpr}$ & $\lambda$=0.25, $\beta$=10, $\gamma$=0.1, h=5, l=1 &
	%\rule{-2pt}{3ex}
      \underline{0.2026}  & 0.0791 
      & $\lambda$=50, $\beta$=50, $\gamma$=50, h=5, l=1  &
      \underline{0.012}  & 0.0418 \\
    \end{tabular}
    
    %\begin{tabular}{ |p{1.5cm}|p{1.5cm}|p{1cm}|p{1cm}|p{1.5cm}|p{1cm}|p{1cm}| }
    \begin{tabular}{
      p{1.5cm}p{1.2cm}p{1cm}p{1.45cm}p{1.5cm}p{1.1cm}p{1.32cm} }
      \hline
      \\
      \multicolumn{1}{c}{} &
      \multicolumn{3}{c}{\textbf{\AMAZON}} & 
      \multicolumn{3}{c}{\textbf{\BX}} \\ 
      \hline
      %\multicolumn{1}{|c|}{} &
      %\multicolumn{1}{|c|}{Params} &
      %\multicolumn{1}{|c|}{Rec@10} &
      %\multicolumn{1}{|c|}{DCG@10} &
      %\multicolumn{1}{|c|}{Params} &
      %\multicolumn{1}{|c|}{Rec@10} &
      %\multicolumn{1}{|c|}{DCG@10} \\
      \\
	%\rule{-2pt}{3ex}
      \COSIM  & - & 0.1732 & 0.0221 & - & 0.1485 & 0.0148 \\
      \\
	%\rule{-2pt}{3ex}
      \RLFMI  & $h$=100, $\lambda$=0.01 & 0.014 & 0.0020  & $h$=100, $\lambda$=0.01 & 0.063 &0.0072\\ 
      \\

      %TODO: full set of regularization parameters
	%\rule{-2pt}{3ex}
      $\CFLIN_{bpr}$ 
      & $l$=3, $\mu_1$=0.1, $\gamma$=0.1 & \underline{0.2054}  & 0.0280 
      & $l$=2, $\mu_1$=0.1, $\gamma$=0.01 & 0.1979 & \underline{0.0211}  \\
      \\
	%\rule{-2pt}{3ex}
      $\CF_{bpr}$ 
      & $\lambda$=1, $\beta$=10000, $\gamma$=1, h=5, l=3  & 0.2046 & \underline{0.0283} 
      & $\lambda$=0.1, $\beta$=1, $\gamma$=0.01, h=1, l=1  & \underline{0.1985} & \underline{0.0211} \\
      \hline
    \end{tabular}
    \begin{tablenotes}
    \item[]\scriptsize
      The ``Params'' column shows the main parameters for each method.  
      For $\CFLIN_{bpr}$, $l$ is the number of similarity functions, and 
      $\mu_1$ is the regularization parameter.
      For $\CF_{bpr}$, $l$ is the number of similarity functions, $\lambda$,
      $\beta$ and $\gamma$ are regularization parameters and $h$ is dimension of feature latent factors. 
      The ``Rec@10'' and ``DCG@10'' columns show the values obtained for these evaluation metrics. 
      The entries that are underlined represent the best performance obtained for each dataset. 
    \end{tablenotes}

 
  \end{threeparttable}
\end{table*}

In this section we will compare \CF with the other competing methods and discuss the
effect of increasing the number of global similarity functions and the dimension of
feature's factor. We will also analyze pairs of feature whose bilinear interaction
contributes the most towards the performance on the dataset \MLHR.

\subsection{Comparison with previous methods}
We compared the performance of \CF with other methods described in Section
\ref{other_methods}.
Results are shown in Table \ref{table_perf_datasets} for different datasets. 
We tried different values for various parameters e.g., latent factors and regularization parameters
associated with methods and report the best results found across datasets.

%\subsection{Performance on Benchmark Data} 
\iffalse

\begin{figure}
  \centering
  \subfloat[ML-HR]{%
    \includegraphics[scale=0.4]{facDim_recall_mlhr}}
  \quad
  \subfloat[CUL]{%
    \includegraphics[scale=0.4]{facDim_recall_cul}}
  \caption{Effect of latent factors on recall}
  \label{latFacEffect}
\end{figure}
\fi

\iffalse

\begin{figure}[h!]
  \centering
  \subfloat[ML-HR]{%
    \includegraphics[scale=0.4]{nSim_recall_mlhr}}
  \quad
  \subfloat[CUL]{%
    \includegraphics[scale=0.4]{nSim_recall_cul}}
  \caption{Effect of number of global similarity functions on recall}
  \label{nSimEffect}
\end{figure}

\fi


\def\arraystretch{1.5}%  1 is the default, change whatever you need
%We plotted the recall performance on
%test against number of global similarity functions in Figure \ref{nSimEffect}.
%Both \CFLIN and \CF continues to provide better
%personalized recommendations with more number of global similarity functions
%shared among them. 


These results show that the relative performance of the \CF over \CFLIN is dataset
dependent. For some datasets, \CF is able to improve the performance whereas 
for the others it does not lead to any improvements.

In order to better characterize and understand the nature of the datasets for
which \CF leads to better results, we analyzed for each dataset the set of users
for which the \CF leads to an increase, no change and a decrease in
performance over \CFLIN. We present these results in Table \ref{USER_INV}. 
For the \MLHR dataset more users benefited from changing to \CF from \CFLIN,
while for the other datasets 
the number of users that benefited from both the methods remains the same. 
\MLHR in comparison to other datasets has more preferences per item, 
hence \CF takes advantage of availability of more data while $\CFLIN$ fails to do the same. 


%================================================================================
\begin{table*}[bt]
  \centering
  \caption{User level investigation for datasets}\label{USER_INV}
  \begin{tabular}{ p{2.2cm} p{2cm} c c p{2.0cm} p{2.0cm} }
    \hline
    \textbf{Dataset} &\textbf{$\CF$ against $\CFLIN$} & \textbf{users} &
      \textbf{items} & \textbf{average user preferences} & \textbf{average item
  preferences} \\ 
    \hline
    \multirow{3}{*}{\MLHR} & BETTER & 897 & 5791 & 348 & 54 \\ 
                             & SAME & 1149 & 5526 & 154 & 32 \\ 
                             & WORSE & 62 & 4403 & 435 & 6 \\ 
    \hline
    \multirow{3}{*}{\AMAZON} & BETTER &  99 &  3530 &  48& 1 \\ 
                             & SAME & 6178 & 9074 & 15 & 10 \\ 
                             & WORSE & 85 & 1728 & 23 & 1 \\ 
    \hline
    \multirow{3}{*}{\CULEXP} & BETTER & 32 & 2491  & 94  & 1 \\ 
                          & SAME & 3136 & 12901 & 32  & 8 \\ 
                          & WORSE & 30 & 2170 & 82 & 1 \\ 
    \hline
    \multirow{3}{*}{\BX}  &  BETTER & 18 & 4044  & 260 & 1  \\ 
                          &  SAME & 2838 & 34042 & 95 & 8 \\ 
                          &  WORSE & 8 & 3313 & 428 & 1 \\ 
    \hline
  \end{tabular}
\end{table*}



\subsection{Effect of increasing the number of global similarity functions}

%TODO: discuss with George how to write that due to computational limitation
%couldn't complete the model training and evaluation in some cases for high
%number of global similarity function

Table \ref{table_global_sim_funcs} shows the performance achieved by using 
the different number of global similarity functions across different datasets. 

For high-dimensional feature datasets (\CULEXP, \AMAZON and \BX) the 
performance remains similar on increasing the number of global similarity
functions. The \CF method performs reasonably well using fewer global similarity 
functions. Therefore similar to \CFLIN, \CF can capture  diverse preferences 
from the users successfully.

For the low-dimensional feature dataset (\MLHR) the performance decreases with
number of global similarity functions. \CF requires a single global similarity
function to achieve the best performance on \MLHR.


%TODO: write tentative explainations

\begin{table*}[hbt]%\footnotesize
  \centering
  \caption {Effect of increasing number of global similarity functions}
  \label{table_global_sim_funcs}
  \begin{threeparttable}
    \centering
    \begin{tabular}{p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}}
      \hline
      %\multicolumn{1}{|p{3cm}|}{\textbf{No. of Global \\Similarity Functions}} &
      \multicolumn{1}{p{2cm}}{\centering No. of Global \\ Similarity Functions} &
      \multicolumn{2}{c}{\textbf{\CULEXP}} &
      \multicolumn{2}{c}{\textbf{\MLHR}} &
      \multicolumn{2}{c}{\textbf{\AMAZON}} &
      \multicolumn{2}{c}{\textbf{\BX}} \\
      \hline
      \multicolumn{1}{c}{} &
      \multicolumn{1}{c}{Rec@10} &
      \multicolumn{1}{p{1cm}}{\centering Factor \\ Dim.} &
      \multicolumn{1}{c}{Rec@10} &
      \multicolumn{1}{p{1cm}}{\centering Factor \\ Dim.} &
      \multicolumn{1}{c}{Rec@10} &
      \multicolumn{1}{p{1cm}}{\centering Factor \\ Dim.} &
      \multicolumn{1}{c}{Rec@10} &
      \multicolumn{1}{p{1cm}}{\centering Factor \\ Dim.} \\
      \hline
      1 & 0.2026 & 5 & 0.0119 & 5 & 0.2053 & 0 & 0.1985 & 1 \\
      2 & 0.2023 & 5 & 0.0098 & 3 & 0.2052 & 0  & 0.1982 & 1  \\
      3 & 0.2017 & 0 & 0.0083 & 10  & 0.2054 & 0  & 0.1980 & 1 \\
      5 & - & - & 0.0076 & 10  & - & - & - & - \\
      7 & - & - & 0.0082 & 10 & - & - & - & - \\
      \hline
    \end{tabular}
    \begin{tablenotes}
    \item[]\scriptsize
      The ``Rec@10'' columns shows the best recall obtained
      for given number of global similarity functions.
      ``Factor Dim.'' column shows the dimension of factors at which best
      recall was achieved. ``Factor Dim.'' of $0$ corresponds to \CFLIN method. 
    \end{tablenotes}
  \end{threeparttable}
\end{table*}


\subsection{Effect of increasing the dimension of feature's factor}

Table \ref{table_feature_fac_dim} shows the effect of increasing the dimension of
feature's factor on the performance across different datasets.  
For all datasets smaller dimension of feature's factor are enough to achieve the best 
performance; however, it may use multiple global similarity functions for the
same. 

\begin{table*}[hbt]%\footnotesize
  \centering
  \caption {Effect of increasing the dimension of feature's factor}
  \label{table_feature_fac_dim}
  \begin{threeparttable}
    \centering
    \begin{tabular}{p{1cm}p{1cm}p{1.2cm}p{1cm}p{1.2cm}p{1cm}p{1.2cm}p{1cm}p{1.2cm}}
      \hline
      \multicolumn{1}{p{2cm}}{\centering Dimension of \\ feature's factor} &
      \multicolumn{2}{c}{\textbf{\CULEXP}} &
      \multicolumn{2}{c}{\textbf{\MLHR}} &
      \multicolumn{2}{c}{\textbf{\AMAZON}} &
      \multicolumn{2}{c}{\textbf{\BX}} \\
      \hline
      \multicolumn{1}{c}{} &
      \multicolumn{1}{c}{Rec@10} &
      \multicolumn{1}{p{1cm}}{\centering No. of global \\ similarity func.} &
      \multicolumn{1}{c}{Rec@10} &
      \multicolumn{1}{p{1cm}}{\centering No. of global \\ similarity func.} &
      \multicolumn{1}{c}{Rec@10} &
      \multicolumn{1}{p{1cm}}{\centering No. of global \\ similarity func.} &
      \multicolumn{1}{c}{Rec@10} &
      \multicolumn{1}{p{1cm}}{\centering No. of global \\ similarity func.} \\
      \hline
      0 & 0.2017 & 1 & 0.0074 & 1 & 0.2054 & 3 & 0.1979 & 2 \\
      1 & 0.2015 & 1 & 0.0079 & 3 & 0.2044 & 3 & 0.1985 & 1 \\
      3 & 0.2021 & 1 & 0.0098 & 2 & 0.2045 & 3 & 0.1980 & 1 \\
      5 & 0.2026 & 1 & 0.0119 & 1 & 0.2046 & 3 & 0.1981 & 2 \\
      7 & - & - & 0.0115 & 1 & - & - & - & - \\
      10 & - & - & 0.009 & 1 & - & - & - & - \\
      \hline
    \end{tabular}
    \begin{tablenotes}
    \item[]\scriptsize
      The ``Rec@10'' columns shows the best recall obtained
      for given dimension of feature's factor.
    \end{tablenotes}
  \end{threeparttable}
\end{table*}


\subsection{Pairwise feature interaction analysis}
For \MLHR dataset we identified pairs of features (genres), such that the bilinear
interaction among these pairs contribute most towards the performance of \CF.
Some of these significant pairs of feature are shown in Table \ref{table_feat_interac}. We
identified these pairs by removing the bilinear interaction between all the possible
pair of features and report those pairs whose removal led to a significant
change in the performance. The pairs which led to a decrease in
the performance are the ones whose interaction contribute towards generating better
recommendations, on the other hand the pairs which led to an increase in the performance are
redundant e.g., Animation and Children. We looked at how often these feature pairs 
occur together for items and found that the frequency of these feature
pairs' co-occurrence is small and that is the reason why a linear model (\CFLIN) fails to capture
the interaction between these pairs, whereas a bilinear model (\CF) performs better.

\begin{table*}[hbt]%\footnotesize
  \centering
  \caption {Significant feature pairs}
  \label{table_feat_interac}
  \begin{threeparttable}
    \centering
    \begin{tabular}{p{2cm}p{2cm}cp{2cm}p{2cm}c}
      \hline
      %\multicolumn{1}{|p{3cm}|}{\textbf{No. of Global \\Similarity Functions}} &
       \textbf{Feature 1} &
       \textbf{Feature 2} & 
       \textbf{Recall change(\%)} &
       \textbf{Feature 1} &
       \textbf{Feature 2} & 
       \textbf{Recall change(\%)} \\
      \hline
      Drama & IMAX & -28.672& Crime & IMAX & 2.485\\
      Children & Drama & -19.790  & Animation & Fantasy & 2.488\\
      Drama & Musical & -13.953  & Adventure & Musical & 2.602 \\
      Fantasy & Drama & -11.596 & Drama  & Documentary & 2.802 \\
      Children & IMAX & -6.185 & Adventure & Animation & 3.369 \\
      Children & Comedy & -6.118 & Animation & Musical & 4.084  \\
      Children & Musical & -5.641 & Animation & Comedy & 4.468 \\
      Drama & Western & -4.902 & Adventure & Drama & 4.476 \\
      Romance & IMAX & -3.912 & Animation & Children & 5.484 \\
      Animation & Film-Noir & -3.360 & Animation & Drama & 7.451 \\
      \hline
    \end{tabular}
  \end{threeparttable}
\end{table*}


\subsection{Discussion}
In our experiments the performance of the bilinear model is found to be dependent on
the datasets. It outperformed the linear model by a significant margin when the 
dimension of the features in the datasets were small. 
The linear model is designed to recommend those items that have common features with the
items preferred by the user. The bilinear model in addition to common features
among items also take into account the features that do not co-occur among the items. 
The low dimensional feature dataset e.g., \MLHR contains features which are disjoint and do not co-occur
frequently among the items. The high dimensional features in our datasets are derived from text and these
may contain terms which co-occur frequently among the items. For example, in the task of scientific articles recommendation, consider a user
who prefers articles related to \textit{machine learning} and \textit{high-performance computing}.
The articles related to \textit{high-performance computing} may contain terms that are
related to \textit{machine learning} e.g., an article describing parallel implementation
of the LASSO method. Due to these terms the linear model can recommend articles
that are related to machine learning from a high performance computing article.
While in the task of movies recommendation the movies are presented by their
corresponding genres, consider a user who prefers \textit{children} and 
\textit{IMAX} movies.  Here the bilinear model can recommend
\textit{IMAX} movies to a person who prefers \textit{children} movies while
linear model can not perform such recommendations.

\afterpage{\clearpage}






